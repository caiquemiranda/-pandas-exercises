{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão de Python Neste Jupyter Notebook: 3.10.5\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão de Python Neste Jupyter Notebook:', python_version())\n",
    "\n",
    "# usaremos o filtro 'warning' para deixar mais limpo.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/cars.csv'\n",
    "dir = 'data/cars.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011',\n",
    "                 '20120303', '2013/04/04',\n",
    "                 '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. How to get the day of month, week number, day of year and day of week from a series of date strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', \n",
    "                 '20120303', '2013/04/04',\n",
    "                 '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week :  [53, 5, 9, 14, 19, 23]\n",
      "Day of year:  [1, 33, 63, 94, 125, 157]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# day of month\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "\n",
    "# week number\n",
    "print(\"Week : \", ser_ts.dt.weekofyear.tolist())\n",
    "\n",
    "# day of year\n",
    "print(\"Day of year: \", ser_ts.dt.dayofyear.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010-01-04', '2011-02-04', '2012-03-04']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2\n",
    "ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. How to filter words that contain atleast 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "emails = pd.Series(['buying books at amazom.com',\n",
    "                    'artui@guthn.com',\n",
    "                    'aroiz@t.co',\n",
    "                    'arionea@mier.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     artui@guthn.com\n",
       "2          aroiz@t.co\n",
       "3    arionea@mier.com\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1 (as series of strings)\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    []\n",
       "1     [artui@guthn.com]\n",
       "2          [aroiz@t.co]\n",
       "3    [arionea@mier.com]\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2 (as series of list)\n",
    "emails.str.findall(pattern, \n",
    "                   flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artui@guthn.com', 'aroiz@t.co', 'arionea@mier.com']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 3 (as list)\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     4.333333\n",
       "banana    6.600000\n",
       "carrot    4.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. How to compute the euclidean distance between two series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "sum((p - q) ** 2) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution (using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. How to find all the local maxima (or peaks) in a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 29.  How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "my_str = 'dbc deb abed gade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "\n",
    "print(freq)\n",
    "\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    4\n",
       "2000-01-08    4\n",
       "2000-01-15    5\n",
       "2000-01-22    9\n",
       "2000-01-29    2\n",
       "2000-02-05    7\n",
       "2000-02-12    6\n",
       "2000-02-19    2\n",
       "2000-02-26    2\n",
       "2000-03-04    8\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(np.random.randint(1,10,10), \n",
    "                pd.date_range('2000-01-01', periods = 10, freq = 'W-SAT'))\n",
    "ser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series([1,10,3, np.nan], \n",
    "                index=pd.to_datetime(['2000-01-01', \n",
    "                                      '2000-01-03',\n",
    "                                      '2000-01-06',\n",
    "                                      '2000-01-08']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02     1.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04    10.0\n",
       "2000-01-05    10.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser.resample('D').ffill() # fill with previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatives\n",
    "ser.resample('D').bfill() # fill with next value\n",
    "ser.resample('D').bfill().ffill() # fill next else prev value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. How to compute the autocorrelations of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07, 0.25, 0.2, -0.49, 0.1, -0.24, 0.11, 0.55, 0.12, 0.39]\n",
      "Lag having highest correlation:  8\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33. How to import only every nth row from a csv file to create a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Use chunks and for-loop\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/bostonhousing.csv',\n",
    "                 chunksize = 50)\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/bostonhousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], \n",
    "                axis = 1)\n",
    "\n",
    "df2 = df2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  zn  indus chas    nox     rm   age     dis rad  tax ptratio  \\\n",
      "0  0.21977   0   6.91    0  0.448  5.602    62  6.0877   3  233    17.9   \n",
      "1   0.0686   0   2.89    0  0.445  7.416  62.5  3.4952   2  276      18   \n",
      "2  2.73397   0  19.58    0  0.871  5.597  94.9  1.5257   5  403    14.7   \n",
      "3   0.0315  95   1.47    0  0.403  6.975  15.3  7.6534   3  402      17   \n",
      "4  0.19073  22   5.86    0  0.431  6.718  17.5  7.8265   7  330    19.1   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0   396.9   16.2  19.4  \n",
      "1   396.9   6.19  33.2  \n",
      "2  351.85  21.45  15.4  \n",
      "3   396.9   4.56  34.9  \n",
      "4  393.74   6.56  26.2  \n"
     ]
    }
   ],
   "source": [
    "# Solution 3: Use csv reader\n",
    "import csv\n",
    "\n",
    "with open('data/bostonhousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df2.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 34. How to change column values when importing csv to a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/bostonhousing.csv',\n",
    "                 converters = {'medv': lambda x: 'High' if float(x) > 25 else 'Low'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.00632 18  2.31  0  0.538  6.575  65.2    4.09  1  296  15.3   396.9  \\\n",
      "0  0.02731  0  7.07  0  0.469  6.421  78.9  4.9671  2  242  17.8   396.9   \n",
      "1  0.02729  0  7.07  0  0.469  7.185  61.1  4.9671  2  242  17.8  392.83   \n",
      "2  0.03237  0  2.18  0  0.458  6.998  45.8  6.0622  3  222  18.7  394.63   \n",
      "3  0.06905  0  2.18  0  0.458  7.147  54.2  6.0622  3  222  18.7   396.9   \n",
      "4  0.02985  0  2.18  0  0.458   6.43  58.7  6.0622  3  222  18.7  394.12   \n",
      "\n",
      "   4.98   Low  \n",
      "0  9.14   Low  \n",
      "1  4.03  High  \n",
      "2  2.94  High  \n",
      "3  5.33  High  \n",
      "4  5.21  High  \n"
     ]
    }
   ],
   "source": [
    "# Solution 2: Using csv reader\n",
    "import csv\n",
    "\n",
    "with open('data/bostonhousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "            out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 35. How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "L = pd.Series(range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len = 2, window_len = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 36. How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/bostonhousing.csv',\n",
    "                 usecols = ['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n"
     ]
    }
   ],
   "source": [
    "# number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# datatypes\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df_stats = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array\n",
    "df_arr = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 38. How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "df.values(row[0], 'Price')\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers.\n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 39. How to rename a specific columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Step 1:\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 40. How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caiquemiranda/pandas-exercises/main/data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Caique Miranda\n",
      "\n",
      "Github username: caiquemiranda\n",
      "\n",
      "numpy : 1.23.0\n",
      "pandas: 1.4.3\n",
      "re    : 2.2.1\n",
      "csv   : 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
